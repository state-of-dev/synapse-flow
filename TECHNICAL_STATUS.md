# OneShot - Estado TÃ©cnico del Proyecto

**VersiÃ³n:** Synapse Flow v1.0.0
**Ãšltima actualizaciÃ³n:** 26 de octubre de 2025
**Commit actual:** `78d00e8 OneShot Synapse`

---

## ğŸ“‹ Resumen Ejecutivo

OneShot es una aplicaciÃ³n de chat con IA de prÃ³xima generaciÃ³n que implementa un **sistema de orquestaciÃ³n dual**: permite interactuar con un solo modelo o enviar consultas a mÃºltiples modelos en paralelo para obtener respuestas consolidadas mediante razonamiento avanzado.

**Stack tecnolÃ³gico principal:**
- Next.js 15 (App Router)
- React 19 RC + TypeScript
- PostgreSQL (Neon) + Drizzle ORM
- Groq API + Cerebras AI + OpenRouter
- Vercel AI SDK
- Tailwind CSS + Radix UI

---

## ğŸ—ï¸ Arquitectura del Sistema

### Modos de OperaciÃ³n

#### 1. **Modo Single Model**
- Usuario selecciona un modelo especÃ­fico de Groq
- La consulta se envÃ­a directamente a ese modelo
- Respuesta Ãºnica con razonamiento extraÃ­do (tags `<think>`)
- Soporte para visiÃ³n multimodal (imÃ¡genes)

#### 2. **Modo Orchestra** (Send to All)
- **Consultas de texto**: Se envÃ­a a 4 modelos de texto en paralelo
  - GPT-OSS 120B
  - Groq Compound
  - Kimi K2
  - Qwen3
- **Consultas con imagen**: Se envÃ­a a 2 modelos de visiÃ³n
  - Llama 4 Maverick
  - Llama 4 Scout
- Respuestas individuales + mega-resumen generado por Cerebras
- ConsolidaciÃ³n mediante modelo de razonamiento

---

## ğŸ“‚ Estructura del Proyecto

```
oneshot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (chat)/
â”‚   â”‚   â”œâ”€â”€ page.tsx                    # Nueva conversaciÃ³n
â”‚   â”‚   â”œâ”€â”€ chat/[id]/page.tsx          # ConversaciÃ³n existente
â”‚   â”‚   â”œâ”€â”€ layout.tsx                  # Layout con sidebar
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ chat/
â”‚   â”‚       â”‚   â”œâ”€â”€ route.ts            # Endpoint streaming (AI SDK)
â”‚   â”‚       â”‚   â”œâ”€â”€ save/route.ts       # Persistencia a PostgreSQL
â”‚   â”‚       â”‚   â””â”€â”€ schema.ts           # ValidaciÃ³n Zod
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ groq/route.ts               # Proxy a Groq API
â”‚   â”‚   â”œâ”€â”€ cerebras/route.ts           # Proxy a Cerebras AI
â”‚   â”‚   â””â”€â”€ openrouter/route.ts         # Proxy a OpenRouter
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ simple-orchestrator-chat.tsx    # Componente principal de chat
â”‚   â”œâ”€â”€ multimodal-input.tsx            # Input con soporte de archivos
â”‚   â””â”€â”€ elements/
â”‚       â””â”€â”€ prompt-input.tsx            # UI components (textarea, toolbar, submit)
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ models.ts                   # 6 modelos de Groq hardcoded
â”‚   â”‚   â”œâ”€â”€ unified-models.ts           # Sistema unificado Groq + OpenRouter
â”‚   â”‚   â”œâ”€â”€ openrouter-models.ts        # Modelos de OpenRouter
â”‚   â”‚   â”œâ”€â”€ providers.ts                # AI SDK custom provider
â”‚   â”‚   â””â”€â”€ prompts.ts                  # System prompts con artifacts
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ schema.ts                   # Schema Drizzle: User, Chat, Message, Vote
â”‚   â””â”€â”€ types.ts                        # TypeScript types
â””â”€â”€ .env.local                          # Variables de entorno
```

---

## ğŸ”‘ Variables de Entorno

| Variable | Proveedor | Estado | Uso |
|----------|-----------|--------|-----|
| `GROQ_API_KEY` | Groq | âœ… Configurada | AutenticaciÃ³n API Groq |
| `OPENROUTER_API_KEY` | OpenRouter | âœ… Configurada | AutenticaciÃ³n OpenRouter |
| `CEREBRAS_API_KEY` | Cerebras | âš ï¸ Opcional | Fallback con hardcoded default |
| `POSTGRES_URL` | Neon | âœ… Configurada | ConexiÃ³n PostgreSQL |
| `AUTH_SECRET` | NextAuth | âœ… Configurada | AutenticaciÃ³n usuarios |
| `BLOB_READ_WRITE_TOKEN` | Vercel | âœ… Configurada | Almacenamiento de archivos |

---

## ğŸ”„ Flujo de Datos

### Flujo Single Model

```
Usuario escribe mensaje
    â†“
SimpleOrchestratorChat.sendToSingleModel()
    â†“
DetecciÃ³n de imagen â†’ Auto-switch a Llama 4 Maverick (vision)
    â†“
POST /api/groq
    â†“
Groq API (https://api.groq.com/openai/v1/chat/completions)
    â†“
Streaming response
    â†“
ExtracciÃ³n de <think> tags (razonamiento)
    â†“
Agregar mensaje a state (ChatMessage[])
    â†“
saveChatToDB() â†’ POST /api/chat/save
    â†“
PostgreSQL (tabla messages_v2)
```

### Flujo Orchestra Mode

```
Usuario activa "Send to All"
    â†“
SimpleOrchestratorChat.sendToAllModels()
    â†“
Promise.all([
    callGroqAI(GPT-OSS),
    callGroqAI(Groq Compound),
    callGroqAI(Kimi K2),
    callGroqAI(Qwen3)
])
    â†“
Cada respuesta: **Model Name:** [reasoning] + text
    â†“
Concatenar todas las respuestas
    â†“
callCerebrasAI(userMessage + allResponses)
    â†“
POST /api/cerebras (llama3.3-70b con reasoning_effort: medium)
    â†“
Cerebras genera mega-resumen con campo reasoning
    â†“
Agregar 4 mensajes individuales + 1 mega-resumen a state
    â†“
saveChatToDB() â†’ PostgreSQL
```

---

## ğŸ’¾ Base de Datos

### Schema Principal

#### **Tabla: Chat**
```typescript
{
  id: uuid (PK)
  title: text
  userId: uuid (FK â†’ users)
  visibility: 'public' | 'private'
  lastContext: jsonb // { usage: { promptTokens, completionTokens } }
  createdAt: timestamp
}
```

#### **Tabla: messages_v2**
```typescript
{
  id: uuid (PK)
  chatId: uuid (FK â†’ chats)
  role: 'user' | 'assistant'
  parts: jsonb[] // Array de { type, text, mediaType, name, url }
  createdAt: timestamp
}
```

#### **Tipos de Parts**
- `text`: Contenido de texto plano
- `file`: Archivos adjuntos (imÃ¡genes, documentos)
- `reasoning`: Fragmentos de razonamiento extraÃ­dos de `<think>` tags

#### **Modo Sin AutenticaciÃ³n**
- Usuario fijo: `00000000-0000-0000-0000-000000000001`
- Todos los chats se asignan a este usuario por defecto

---

## ğŸ¤– Modelos Integrados

### Groq Models (en SimpleOrchestratorChat)

**Modelos de Texto:**
1. `gpt-oss-120b` - GPT-OSS 120B
2. `groq-compound` - Groq Compound
3. `llama-4-maverick` - Llama 4 Maverick (tambiÃ©n visiÃ³n)
4. `llama-4-scout` - Llama 4 Scout (tambiÃ©n visiÃ³n)
5. `kimi-k2` - Kimi K2
6. `qwen3` - Qwen3

**Modelos de VisiÃ³n:**
1. `llama-4-maverick` - Llama 4 Maverick
2. `llama-4-scout` - Llama 4 Scout

### Modelos en lib/ai/models.ts (6 modelos validados)
1. `deepseek-chat` - DeepSeek Chat (default)
2. `deepseek-reasoner` - DeepSeek Reasoner
3. `llama-3.3-70b-versatile` - Llama 3.3 70B
4. `llama-4-maverick` - Llama 4 Maverick
5. `mistral-small-latest` - Mistral Small
6. `qwen-2.5-7b-instruct` - Qwen 2.5 7B

### Cerebras (ConsolidaciÃ³n)
- Modelo: `llama3.3-70b`
- ParÃ¡metros: `reasoning_effort: 'medium'`, `max_completion_tokens: 8000`
- Uso: Mega-resumen en modo Orchestra

---

## ğŸ¨ Componentes Frontend

### `SimpleOrchestratorChat` (Principal)

**Estado:**
```typescript
messages: ChatMessage[]
input: string
loading: boolean
selectedGroqModel: { id: string, name: string, supportsVision: boolean }
sendToAll: boolean
attachments: { url: string, name: string, contentType: string }[]
```

**Funciones clave:**
- `sendToSingleModel()`: EnvÃ­a a un solo modelo
- `sendToAllModels()`: OrquestaciÃ³n paralela
- `callGroqAI(model, messages)`: Llamada individual a Groq
- `callCerebrasAI(messages)`: ConsolidaciÃ³n con Cerebras
- `saveChatToDB()`: Persistencia en PostgreSQL
- `extractReasoningFromResponse()`: Parseo de `<think>` tags

**CaracterÃ­sticas:**
- Auto-navegaciÃ³n despuÃ©s del primer mensaje
- Persistencia de input en localStorage
- RevalidaciÃ³n de chat history con SWR
- Manejo de errores y rate limits

### `MultimodalInput`

**Props:**
```typescript
input: string
setInput: (value: string) => void
isLoading: boolean
handleSubmit: (e) => void
attachments: Attachment[]
setAttachments: (files: File[] | ((prev: Attachment[]) => Attachment[])) => void
modelSelect: ReactNode
```

**Funcionalidades:**
- Upload de imÃ¡genes (hasta 5MB cada una)
- ValidaciÃ³n de tipos: image/png, image/jpeg, image/webp
- Preview de imÃ¡genes adjuntas
- Subida a Vercel Blob con progress tracking
- Textarea con auto-resize

---

## ğŸ”§ Endpoints API

### POST `/api/groq`
**DescripciÃ³n:** Proxy directo a Groq API
**Headers:** `Authorization: Bearer $GROQ_API_KEY`
**Body:**
```json
{
  "model": "llama-4-maverick",
  "messages": [
    { "role": "user", "content": "..." }
  ],
  "stream": true
}
```
**Response:** Server-Sent Events (SSE) stream

---

### POST `/api/cerebras`
**DescripciÃ³n:** Proxy a Cerebras AI para razonamiento
**Headers:** `Authorization: Bearer $CEREBRAS_API_KEY`
**Body:**
```json
{
  "model": "llama3.3-70b",
  "messages": [...],
  "reasoning_effort": "medium",
  "max_completion_tokens": 8000
}
```
**Response:** JSON con campo `reasoning`

---

### POST `/api/chat/save`
**DescripciÃ³n:** Guarda chat y mensajes en PostgreSQL
**Body:**
```json
{
  "chatId": "uuid",
  "messages": [
    {
      "id": "uuid",
      "role": "user",
      "parts": [
        { "type": "text", "text": "..." },
        { "type": "file", "url": "...", "mediaType": "image/png" }
      ]
    }
  ]
}
```
**Response:** `{ success: true }`

---

### POST `/api/openrouter`
**DescripciÃ³n:** Proxy a OpenRouter (no utilizado actualmente)
**Estado:** âš ï¸ Definido pero no integrado en UI

---

## âœ¨ CaracterÃ­sticas Destacadas

### 1. **ExtracciÃ³n de Razonamiento**
Los modelos pueden envolver su proceso de pensamiento en tags `<think>`:
```
<think>Primero debo analizar...</think>
La respuesta final es...
```
El componente extrae automÃ¡ticamente el razonamiento y lo almacena como part de tipo `reasoning`.

### 2. **Auto-selecciÃ³n de Modelos de VisiÃ³n**
Cuando se sube una imagen en modo single-model, automÃ¡ticamente cambia a Llama 4 Maverick (modelo con capacidades de visiÃ³n).

### 3. **ConsolidaciÃ³n Inteligente**
En modo Orchestra, Cerebras recibe:
- Consulta original del usuario
- Respuestas de los 4 modelos con prefijos de nombre
- Genera un mega-resumen sintetizado con razonamiento avanzado

### 4. **Persistencia Flexible**
Estructura de `parts` permite almacenar:
- MÃºltiples fragmentos de texto
- Archivos con metadata (URL, tipo MIME, nombre)
- Razonamiento separado del texto final

### 5. **Manejo de Rate Limits**
Detecta respuestas de error de Groq y muestra mensajes amigables al usuario.

---

## ğŸš§ Limitaciones Conocidas

### 1. **Sin Rate Limiting Coordinado**
En modo Orchestra, se envÃ­an 4 requests simultÃ¡neos a Groq. Si hay rate limits por minuto, pueden fallar algunas solicitudes.

**SoluciÃ³n propuesta:** Implementar queue con retraso entre requests o manejar reintentos.

---

### 2. **Provider VacÃ­o en AI SDK**
El archivo `lib/ai/providers.ts` define `myProvider` pero estÃ¡ vacÃ­o en producciÃ³n. El endpoint `/api/chat` (AI SDK) no se utiliza realmente.

**Estado actual:** La orquestaciÃ³n usa llamadas HTTP directas a `/api/groq` y `/api/cerebras` en lugar del AI SDK.

---

### 3. **OpenRouter No Integrado**
Existe proxy en `/api/openrouter` y modelos definidos en `unified-models.ts`, pero no se usan en `SimpleOrchestratorChat`.

**Oportunidad:** Expandir la orquestaciÃ³n para incluir modelos de OpenRouter.

---

### 4. **Sin AutenticaciÃ³n Real**
Todos los chats se asignan al usuario fijo `00000000-0000-0000-0000-000000000001`.

**Estado:** NextAuth configurado pero no implementado en el flujo principal.

---

### 5. **No Hay LÃ­mite de Mensajes en Orchestra**
En modo Orchestra, se guardan todas las respuestas (4 individuales + 1 resumen = 5 mensajes por turno). Esto puede llenar rÃ¡pidamente el contexto.

**SoluciÃ³n propuesta:** Limitar historial o implementar sliding window.

---

## ğŸ“Š MÃ©tricas y Monitoreo

### Guardado en `lastContext`
```json
{
  "usage": {
    "promptTokens": 1234,
    "completionTokens": 567
  }
}
```

**Estado actual:** Se define en schema pero no se popula activamente desde las respuestas de API.

---

## ğŸ” Seguridad

### API Keys
- Almacenadas en variables de entorno
- No expuestas al cliente
- Proxy routes evitan CORS y exposure

### Upload de Archivos
- ValidaciÃ³n de tipo MIME
- LÃ­mite de tamaÃ±o: 5MB por archivo
- Almacenamiento en Vercel Blob (aislado)

### InyecciÃ³n SQL
- Protegido por Drizzle ORM con queries parametrizadas

---

## ğŸ§ª Testing

**Estado actual:** âš ï¸ No hay tests implementados

**Archivos de configuraciÃ³n:**
- Mock provider en `lib/ai/providers.ts` para entorno test
- No se encontraron archivos `.test.ts` o `.spec.ts`

---

## ğŸ“¦ Dependencias Principales

```json
{
  "next": "15.0.3",
  "react": "19.0.0-rc",
  "ai": "^5.0.26",
  "drizzle-orm": "^0.38.3",
  "@vercel/blob": "^0.30.0",
  "next-auth": "5.0.0-beta.25",
  "zod": "^3.24.1",
  "tailwindcss": "^3.4.17",
  "@radix-ui/react-dialog": "^1.1.4"
}
```

---

## ğŸ¯ Roadmap y Mejoras Sugeridas

### Alta Prioridad
1. âœ… **IntegraciÃ³n de audio** (Whisper STT + TTS de Groq)
2. ğŸ”„ **Rate limiting inteligente** en modo Orchestra
3. ğŸ”„ **AutenticaciÃ³n real** con NextAuth
4. ğŸ”„ **Sistema de crÃ©ditos/tokens** para usuarios

### Media Prioridad
5. ğŸ”„ **IntegraciÃ³n OpenRouter** en UI
6. ğŸ”„ **Tests unitarios y E2E**
7. ğŸ”„ **MÃ©tricas de uso** (tracking de tokens)
8. ğŸ”„ **ExportaciÃ³n de conversaciones** (PDF, Markdown)

### Baja Prioridad
9. ğŸ”„ **Temas personalizables**
10. ğŸ”„ **BÃºsqueda en historial**
11. ğŸ”„ **Compartir conversaciones pÃºblicas**

---

## ğŸ› Issues Conocidos

### 1. Dark Mode Toggle
**Commit:** `369673f dark mode fix`
**Estado:** Resuelto en commit reciente

### 2. Modo Aethra
**Commit:** `929f5e5 iniciar en modo aethra off`
**DescripciÃ³n:** Modo especial que se desactiva por defecto
**Estado:** âš ï¸ No documentado en cÃ³digo visible

---

## ğŸ“ Notas de Desarrollo

### Convenciones de CÃ³digo
- TypeScript estricto
- Componentes funcionales con hooks
- Server Components por defecto (Next.js 15)
- Client Components marcados con `'use client'`

### Estructura de Commits
```
78d00e8 OneShot Synapse
369673f dark mode fix
929f5e5 iniciar en modo aethra off
d755ac3 Synapse Flow v1.0.0
```

---

## ğŸŒ Deployment

**Plataforma:** Vercel (inferido por uso de Vercel Blob)
**Rama principal:** `master`
**Estado del repositorio:** Clean (sin cambios pendientes)

---

## ğŸ“ Contacto y Soporte

**Proyecto:** OneShot - Synapse Flow
**VersiÃ³n:** v1.0.0
**Ãšltima actualizaciÃ³n:** Commit `78d00e8`

---

## ApÃ©ndice A: Ejemplo de Message Object

```json
{
  "id": "msg_123",
  "role": "assistant",
  "parts": [
    {
      "type": "reasoning",
      "text": "Primero debo analizar el contexto..."
    },
    {
      "type": "text",
      "text": "BasÃ¡ndome en mi anÃ¡lisis, la respuesta es..."
    }
  ]
}
```

## ApÃ©ndice B: Ejemplo de Orchestra Response

**User:** "Â¿CuÃ¡l es la capital de Francia?"

**Respuestas individuales:**
1. **GPT-OSS 120B:** La capital de Francia es ParÃ­s...
2. **Groq Compound:** ParÃ­s es la capital de Francia...
3. **Kimi K2:** La respuesta es ParÃ­s...
4. **Qwen3:** Francia â†’ capital â†’ ParÃ­s

**Mega-resumen (Cerebras):**
```json
{
  "reasoning": "Los 4 modelos coinciden unÃ¡nimemente...",
  "text": "ParÃ­s es la capital de Francia. Todos los modelos consultados confirman esta informaciÃ³n con alta confianza."
}
```

---

**Fin del documento tÃ©cnico**